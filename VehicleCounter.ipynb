{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install bytetracker\n",
    "!pip install supervision==0.1.0\n",
    "!pip install yolox\n",
    "\n",
    "!git clone https://github.com/ifzhang/ByteTrack.git\n",
    "!cd ByteTrack && pip3 install -q -r requirements.txt\n",
    "!cd ByteTrack && python3 setup.py -q develop\n",
    "!pip install -q cython_bbox\n",
    "!pip install -q onemetric\n",
    "sys.path.append(f'{os.getcwd()}/ByteTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import supervision\n",
    "from supervision.draw.color import ColorPalette\n",
    "from supervision.geometry.dataclasses import Point\n",
    "from supervision.video.dataclasses import VideoInfo\n",
    "from supervision.video.source import get_video_frames_generator\n",
    "from supervision.video.sink import VideoSink\n",
    "from supervision.notebook.utils import show_frame_in_notebook\n",
    "from supervision.tools.detections import Detections, BoxAnnotator\n",
    "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n",
    "\n",
    "import yolox\n",
    "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
    "from onemetric.cv.utils.iou import box_iou_batch\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe340324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO()\n",
    "model.fuse()\n",
    "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
    "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
    "box_annotator = BoxAnnotator(color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2)\n",
    "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "\n",
    "start_point = Point(0,0)\n",
    "end_point = Point(100,100)\n",
    "\n",
    "yolo_path = \n",
    "video_path = \n",
    "total_frames = \n",
    "\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "CLASS_ID = [2, 3, 5, 7]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BYTETrackerArgs:\n",
    "    track_thresh: float = 0.25\n",
    "    track_buffer: int = 30\n",
    "    match_thresh: float = 0.8\n",
    "    aspect_ratio_thresh: float = 3.0\n",
    "    min_box_area: float = 1.0\n",
    "    mot20: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
    "def detections2boxes(detections):\n",
    "    return np.hstack((\n",
    "        detections.xyxy,\n",
    "        detections.confidence[:, np.newaxis]\n",
    "    ))\n",
    "\n",
    "\n",
    "def tracks2boxes(tracks):\n",
    "    return np.array([\n",
    "        track.tlbr\n",
    "        for track\n",
    "        in tracks\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "\n",
    "# matches our bounding boxes with predictions\n",
    "def match_detections_with_tracks(detections, tracks):\n",
    "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
    "        return np.empty((0,))\n",
    "\n",
    "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
    "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
    "    track2detection = np.argmax(iou, axis=1)\n",
    "    \n",
    "    tracker_ids = [None] * len(detections)\n",
    "    \n",
    "    for tracker_index, detection_index in enumerate(track2detection):\n",
    "        if iou[tracker_index, detection_index] != 0:\n",
    "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
    "\n",
    "    return tracker_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73550507",
   "metadata": {},
   "outputs": [],
   "source": [
    "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
    "    # loop over video frames\n",
    "    for frame in tqdm(generator, total=video_info.total_frames):\n",
    "        # model prediction on single frame and conversion to supervision Detections\n",
    "        results = model(frame)\n",
    "        detections = Detections(\n",
    "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "        )\n",
    "        # filtering out detections with unwanted classes\n",
    "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # tracking detections\n",
    "        tracks = byte_tracker.update(\n",
    "            output_results=detections2boxes(detections=detections),\n",
    "            img_info=frame.shape,\n",
    "            img_size=frame.shape\n",
    "        )\n",
    "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
    "        detections.tracker_id = np.array(tracker_id)\n",
    "        # filtering out detections without trackers\n",
    "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
    "        detections.filter(mask=mask, inplace=True)\n",
    "        # format custom labels\n",
    "        labels = [\n",
    "            f\"#{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "            for _, confidence, class_id, tracker_id\n",
    "            in detections\n",
    "        ]\n",
    "        # updating line counter\n",
    "        line_counter.update(detections=detections)\n",
    "        # annotate and display frame\n",
    "        frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
    "        line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
    "        sink.write_frame(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac780973",
   "metadata": {},
   "source": [
    "# Changes to Make to Streamlit App\n",
    "- Change tracker hyperparameters\n",
    "- add polygons/lines from file\n",
    "- include link to polygon creator\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
