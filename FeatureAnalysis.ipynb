{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407a795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba01445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_analyzed_edge(full_path):\n",
    "    temp_df = pd.read_csv(full_path)\n",
    "    temp_df['period_score'] = (1 < temp_df['period']) | (temp_df['period'] < 4)\n",
    "    temp_df['maxcov_score'] = temp_df['maxcov'] < .2\n",
    "    temp_df['amp_score'] = (4 < temp_df['amp']) |(temp_df['amp'] < 20)\n",
    "    temp_df['sum_score'] = temp_df.loc[:,['period_score','maxcov_score','amp_score']].astype(int).sum(axis=1)\n",
    "    temp_df['total_score'] = temp_df['sum_score'].sum()\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b67bb18d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'analyzed_edges/'\n",
    "files = [file for file in os.listdir(DATA_DIR) if file.startswith('edge_analysis') and file.endswith('.csv')]\n",
    "df_dict = dict()\n",
    "for file in files[:10]:\n",
    "    full_path = os.path.join(DATA_DIR, file)\n",
    "    date = file.replace('.csv','')\n",
    "    temp_df = read_analyzed_edge(full_path)\n",
    "    display(temp_df.head())\n",
    "    df_dict[date] = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63df7f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-15</th>\n",
       "      <td>190</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-16</th>\n",
       "      <td>287</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-05</th>\n",
       "      <td>272</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>194</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>428</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-07</th>\n",
       "      <td>195</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-16</th>\n",
       "      <td>247</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>342</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-30</th>\n",
       "      <td>136</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-12</th>\n",
       "      <td>66</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            xmin  xmax\n",
       "date                  \n",
       "2019-12-15   190   489\n",
       "2021-07-16   287   629\n",
       "2021-12-05   272   531\n",
       "2019-12-23   194   502\n",
       "2017-01-05   428   711\n",
       "...          ...   ...\n",
       "2017-01-07   195   590\n",
       "2021-01-16   247   590\n",
       "2017-11-21   342   647\n",
       "2017-01-30   136   574\n",
       "2021-11-12    66   328\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_tf_csv(csv_path='tflabels.csv'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    CROP_DIFS = (125, 844, 153, 454)\n",
    "    def get_date(x):\n",
    "        split_x = x.split('_')\n",
    "        return split_x[1] if split_x[0] == 'spots' else split_x[0]\n",
    "    \n",
    "    df['filename'] = df['filename'].apply(get_date)\n",
    "    df = df.rename(columns={'filename':'date'})\n",
    "    wide_indices = df['width'] == 1000\n",
    "    df.loc[wide_indices,['xmin','xmax']] -= CROP_DIFS[0]\n",
    "#     df.loc[wide_indices,['ymin','ymax']] -= CROP_DIFS[2]\n",
    "    df = df.drop(columns=['width','height','class','ymin','ymax']).set_index('date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df\n",
    "\n",
    "tf_df = read_tf_csv()\n",
    "display(tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea1743bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_yolo_dir(parent_dir, img_width=719, csv_path='date_labels.csv'):\n",
    "    full_csv_path = os.path.join(parent_dir, csv_path)\n",
    "    if os.path.exists(full_csv_path):\n",
    "        print(f'File {full_csv_path} already found, returning')\n",
    "        truth_df = pd.read_csv(full_csv_path)\n",
    "        return truth_df\n",
    "    \n",
    "    truth_df_cols = list()\n",
    "    for file in os.listdir(parent_dir):\n",
    "        date = file.split('_', 1)[0].replace('.txt','')\n",
    "        new_name = os.path.join(parent_dir, date + '.txt')\n",
    "        print(new_name)\n",
    "        if not os.path.exists(new_name): os.rename(os.path.join(parent_dir, file), new_name)\n",
    "        with open(new_name, 'r') as f:\n",
    "            truth_arr = np.zeros(img_width, dtype=np.bool_)\n",
    "            for line in f.readlines():\n",
    "                if not line: continue\n",
    "                print(line)\n",
    "                arr = np.array([float(x) for x in line.split(' ')])\n",
    "                assert arr[0] == 0\n",
    "                arr = arr[::2] # grab only the x values\n",
    "                xmin = int(np.amin(arr) * img_width)\n",
    "                xmax = int(np.amax(arr) * img_width)\n",
    "                truth_arr[xmin:xmax] = True\n",
    "            truth_df_cols.append(pd.DataFrame(truth_arr, columns=date))\n",
    "    truth_df = pd.concatenate(truth_df_cols, axis=1)\n",
    "    truth_df.to_csv(full_csv_path)\n",
    "    print(f'File {full_csv_path} created, returning')\n",
    "    return truth_df\n",
    "\n",
    "def preprocess_tf_csv(src_path='tflabels.csv', img_width=719, dest_path='date_labels.csv'):\n",
    "    if os.path.exists(dest_path):\n",
    "        print(f'File {dest_path} already found, returning')\n",
    "        truth_df = pd.read_csv(dest_path)\n",
    "        return truth_df\n",
    "    tf_df = read_tf_csv(csv_path=src_path)\n",
    "    truth_df_cols = list()\n",
    "    for i, tup in tf_df.itertuples():\n",
    "        date = tup.date\n",
    "        truth_arr = np.zeros(img_width, dtype=np.bool_)\n",
    "        xmin = tup.xmin\n",
    "        xmax = tup.xmax\n",
    "        truth_arr[xmin:xmax] = True\n",
    "        truth_df_cols.append(pd.Series(truth_arr, index=date))\n",
    "    truth_df = pd.concatenate(truth_df_cols, axis=1)\n",
    "    truth_df.to_csv(full_csv_path)\n",
    "    print(f'File {dest_path} created, returning')\n",
    "    return truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df0fbf47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     Xy \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(df_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Xy\u001b[38;5;241m.\u001b[39mloc[:,Xy\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m target_col], Xy\u001b[38;5;241m.\u001b[39mloc[:,Xy\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m==\u001b[39m target_col]\n\u001b[1;32m---> 42\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_tf_truth_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[16], line 39\u001b[0m, in \u001b[0;36mconcat_tf_truth_values\u001b[1;34m(csv_path, data_dir, target_col)\u001b[0m\n\u001b[0;32m     37\u001b[0m     temp_df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(temp_df\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     38\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(temp_df)\n\u001b[1;32m---> 39\u001b[0m Xy \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xy\u001b[38;5;241m.\u001b[39mloc[:,Xy\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m target_col], Xy\u001b[38;5;241m.\u001b[39mloc[:,Xy\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m==\u001b[39m target_col]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "def window_label(arr, window_size=240, offset=10):\n",
    "    labels = list()\n",
    "    for i in range(0, len(arr) - window_size, offset):\n",
    "        if np.count_nonzero(arr[i,i+window_size]) <= 0:\n",
    "            labels.append(True)\n",
    "        else:\n",
    "            labels.append(False)\n",
    "    return np.array(labels)\n",
    "\n",
    "def concat_yolo_truth_values(truth_dir='sample_yolo_labels/', data_dir='analyzed_edges/', target_col='lstid_truth'):\n",
    "    truth_df = preprocess_yolo_dir(truth_dir)\n",
    "    files = [file for file in os.listdir(data_dir) if file.startswith('edge_analysis') and file.endswith('.csv')]\n",
    "    df_list = list()\n",
    "    for file in files[:10]:\n",
    "        full_path = os.path.join(data_dir, file)\n",
    "        date = file.replace('.csv','')\n",
    "        temp_df = read_analyzed_edge(full_path)\n",
    "        temp_df['date'] = date\n",
    "        temp_df[target_col] = window_label(truth_df[date])\n",
    "        temp_df.set_index('date', inplace=True)\n",
    "        temp_df.index = pd.to_datetime(temp_df.index)\n",
    "        df_list.append(temp_df)\n",
    "    Xy = pd.concat(df_list, axis=0)\n",
    "    return Xy.loc[:,Xy.columns != target_col], Xy.loc[:,Xy.columns == target_col]\n",
    "\n",
    "def reduce_input_dim(Xy, target_col='lstid_truth'):\n",
    "    row = dict()\n",
    "    row['maxcov_per'] = np.count_nonzero(Xy['maxcov'] < .2)\n",
    "    row['maxcov_avg'] = Xy['maxcov'].loc[Xy['maxcov'] < 1].mean()\n",
    "    \n",
    "    row['amp_per'] = np.count_nonzero(X['amp'] < 20)\n",
    "    row['amp_avg'] = Xy['amp'].loc[Xy['amp'] < 100].mean()\n",
    "    \n",
    "    row['period_per'] = np.count_nonzero(Xy['period'] > 3)\n",
    "    row['period_avg'] = Xy['period'].loc[Xy['period'] < 20].mean()\n",
    "    \n",
    "    row[target_col] = Xy[target_col].sum()\n",
    "    Xy = pd.DataFrame(row)\n",
    "    return Xy\n",
    "\n",
    "def concat_tf_truth_values(csv_path='', data_dir='analyzed_edges/', target_col='lstid_truth', dim=2):\n",
    "    truth_df = preprocess_tf_csv(src_path=csv_path)\n",
    "    files = [file for file in os.listdir(data_dir) if file.startswith('edge_analysis') and file.endswith('.csv')]\n",
    "    df_list = list()\n",
    "    for file in files[:10]:\n",
    "        full_path = os.path.join(data_dir, file)\n",
    "        date = file.replace('.csv','')\n",
    "        temp_df = read_analyzed_edge(full_path)\n",
    "        temp_df['date'] = date\n",
    "        temp_df[target_col] = window_label(truth_df[date])\n",
    "        temp_df.set_index('date', inplace=True)\n",
    "        temp_df.index = pd.to_datetime(temp_df.index)\n",
    "        if dim == 1:\n",
    "            df_list.append(reduce_input_dim(temp_df, target_col=target_col))\n",
    "        elif dim==2:\n",
    "            df_list.append(temp_df)\n",
    "    Xy = pd.concat(df_list, axis=0)\n",
    "    return Xy.loc[:,Xy.columns != target_col], Xy.loc[:,Xy.columns == target_col]\n",
    "\n",
    "X, y = concat_tf_truth_values()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac816ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_tree, plot_tree\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score, average_precision, roc_auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_min_cols(X):\n",
    "    X = X.loc[:,['period','maxcov','amp']]\n",
    "    return X\n",
    "    \n",
    "def split_core_cols(X):\n",
    "    X = X.drop(columns=['period_score','maxcov_score','amp_score','sum_score','total_score'])\n",
    "    return X\n",
    "\n",
    "def split_all_cols(X):\n",
    "    X = X.drop(columns=['sum_score','total_score'])\n",
    "    return X\n",
    "\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.2)\n",
    "# model = LGBMClassifier()\n",
    "scores = list()\n",
    "for max_depth in range(1, 15):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, max_features=X_train.shape[1])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('ROC', roc_auc(y_pred, y_test))\n",
    "    plt.title(max_depth)\n",
    "    plt.show()\n",
    "    scores.append((max_depth, score))\n",
    "\n",
    "x, y = zip(*scores)\n",
    "sns.lineplot(x=x, y=y, palette='viridis')\n",
    "plt.xlabel('Max Tree Depth')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81688706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decision_tree(model, save_path=''):\n",
    "    text_repr = tree.export_text(model)\n",
    "    print(text_repr)\n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(text_repr)\n",
    "    return text_repr\n",
    "\n",
    "def plot_decision_tree(model, save_path='', dpi=300):\n",
    "    plt.figure(figsize=(16,16), dpi=dpi)\n",
    "    plot_tree(\n",
    "        model, \n",
    "        feature_names=model.feature_names_in_, \n",
    "        class_names=['No LSTID','LSTID'], \n",
    "        filled=True\n",
    "    )\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=dpi)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_importance(model, save_path='', dpi=dpi):\n",
    "    plt.figure(figsize=(16,16), dpi=dpi)\n",
    "    data = pd.DataFrame({\n",
    "        'features' : model.feature_names_in_\n",
    "        'importance' : model.feature_importances_,\n",
    "    }).set_index('features')\n",
    "    sns.barplot(data=data, y='importance', hue='importance', palette='flare')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=dpi)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "print_decision_tree(model, save_path='dt_text.txt')\n",
    "plot_decision_tree(model, save_path='dt_info.png')\n",
    "plot_importance(model, save_path='dt_fimp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86900f11",
   "metadata": {},
   "source": [
    "# Decision Tree Information\n",
    "[Decision Tree Function](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)  \n",
    "[Decision Tree Documentation](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning)  \n",
    "[Decision Tree Visualization Walkthrough](https://mljar.com/blog/visualize-decision-tree/)  \n",
    "[TF Decision Forests](https://github.com/tensorflow/decision-forests)  \n",
    "[Light Gradient Boosting Machine](https://lightgbm.readthedocs.io/en/v3.3.2/index.html)  \n",
    "[Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)  \n",
    "[Detailed Tree Visualization](https://github.com/parrt/dtreeviz)  \n",
    "\n",
    "Corrections:\n",
    "- DTs can handle multi-output, RF can with some libraries, gradient boosters cannot\n",
    "- Confidence can easily be shown\n",
    "    \n",
    "Feature Sets:\n",
    "\n",
    "\n",
    "Optimization Problem:\n",
    "- Window-by-window:\n",
    "    - Predict a single value for every window\n",
    "    - Requires label for every window\n",
    "    - More data available\n",
    "    - More outliers by default\n",
    "- Sequence-by-sequence:\n",
    "    - Predict a single value for an entire set \n",
    "    - Requires feature summarization\n",
    "    - Less data available\n",
    "    - Better feature control\n",
    "- Regression:\n",
    "    - Determine value between 0 and 1\n",
    "- Classification:\n",
    "    - Determine class either 0 or 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
